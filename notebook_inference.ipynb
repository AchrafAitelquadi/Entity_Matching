{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "256b5f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from my_code.inference import  blocking_inference, run_blocked_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a972b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(hp, model_path):\n",
    "    \"\"\"\n",
    "    Orchestrate the full blocking + inference pipeline.\n",
    "\n",
    "    1. Run the blocking stage to generate candidate pairs\n",
    "    2. Run the inference stage to score those pairs and\n",
    "       produce the final matched results\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    hp : object\n",
    "        Hyperparameter/configuration object containing file paths,\n",
    "        thresholds, and other settings.\n",
    "    model_path : str\n",
    "        Path to the trained matching model to be used during inference.\n",
    "    \"\"\"\n",
    "\n",
    "    # Step 1: Generate candidate pairs via blocking\n",
    "    blocking_inference(hp)\n",
    "\n",
    "    # Step 2: Score candidate pairs with the trained model and\n",
    "    #         write final matches to CSV\n",
    "    run_blocked_inference(\n",
    "                        model_path=model_path,\n",
    "                        blocked_pairs_csv=hp.output_pairs_csv,\n",
    "                        reference_table_csv=hp.table_reference_csv,\n",
    "                        source_table_csv=hp.table_source_csv,\n",
    "                        output_csv=hp.output_inference_csv,\n",
    "                        lm=hp.lm,\n",
    "                        max_len=hp.max_len\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c78c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_inference = \"D:/Study/ENSIAS/stage_2/ER/ditto/resultat_inference\"   # Base directory for all inference-related files\n",
    "task_inference = \"inference_1\"                                               # Name of the current inference task\n",
    "model_path = r\"D:\\Study\\ENSIAS\\stage_2\\ER\\ditto\\resultat_training\\logs\\Generated_data\\model_Generated_data_bs32_ep1_lmdistilbert_alpha0.8_date2025-09-11.pt\"\n",
    "                                                                             # Trained Ditto model checkpoint to load for inference\n",
    "\n",
    "hp_inference = Namespace(\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "    # Hyperparameters for the **blocking step**\n",
    "    model_name_blocking=\"all-MiniLM-L12-v2\",        # Sentence-transformers model used to create embeddings\n",
    "    top_k_blocking=5,                               # Keep the top-5 most similar candidates for each record\n",
    "    threshold_blocking=0.95,                        # Cosine similarity threshold to filter candidate pairs\n",
    "    batch_size_blocking=512,                        # Batch size for encoding/embedding computation\n",
    "    # -----------------------------------------------------------------------------------------\n",
    "\n",
    "    # Input CSV files (raw entity tables + ground truth for evaluation)\n",
    "    table_reference_csv=f\"{base_path_inference}/data/{task_inference}/reference_table.csv\",  # “Reference” table\n",
    "    table_source_csv=f\"{base_path_inference}/data/{task_inference}/source_table.csv\",        # “Source” table\n",
    "\n",
    "    # Ditto-style TXT files (entity tables converted to text for Ditto model consumption)\n",
    "    table_reference_txt=f\"{base_path_inference}/input_txt_blocking/{task_inference}/reference_table.txt\",\n",
    "    table_source_txt=f\"{base_path_inference}/input_txt_blocking/{task_inference}/source_table.txt\",\n",
    "\n",
    "    # Precomputed embedding vector files (to avoid recomputing sentence embeddings)\n",
    "    table_reference_vec=f\"{base_path_inference}/vectors_blocking/{task_inference}/reference_table.txt.mat\",\n",
    "    table_source_vec=f\"{base_path_inference}/vectors_blocking/{task_inference}/source_table.txt.mat\",\n",
    "\n",
    "    # Blocking outputs (candidate pairs produced by the blocking step)\n",
    "    output_pairs_csv=f\"{base_path_inference}/blocking/{task_inference}/blocking_pairs.csv\",          # Candidate pairs as CSV\n",
    "    output_ditto_txt=f\"{base_path_inference}/blocking/{task_inference}/blocking_pairs_ditto.txt\",    # Same pairs in Ditto TXT format\n",
    "\n",
    "    # Final inference result (predicted matches)\n",
    "    output_inference_csv=f\"{base_path_inference}/inference/{task_inference}/result.csv\",             # Final predicted matches\n",
    "\n",
    "    # Intermediate datasets for Ditto (if you need to re-run or inspect data)\n",
    "    dataset_csv_dir=f\"{base_path_inference}/dataset_ditto_csv\",\n",
    "    dataset_txt_dir=f\"{base_path_inference}/dataset_ditto_txt\",\n",
    "\n",
    "    # Misc task info\n",
    "    task=task_inference,           # Task name, used to organize all path references\n",
    "    lm=\"distilbert\",               # Language model backbone for Ditto inference\n",
    "    max_len=256,                   # Maximum token length for each input pair\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b52251f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning mapping json file done.\n",
      "✅ Normalized and saved CSV at: D:/Study/ENSIAS/stage_2/ER/ditto/resultat_inference/data/inference_1/reference_table.csv\n",
      "Cleaning mapping json file done.\n",
      "✅ Normalized and saved CSV at: D:/Study/ENSIAS/stage_2/ER/ditto/resultat_inference/data/inference_1/source_table.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\anaconda3\\envs\\ditto_env\\Lib\\site-packages\\huggingface_hub\\file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "Processing blocked inference: 100%|██████████| 30/30 [00:02<00:00, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved final results to: D:/Study/ENSIAS/stage_2/ER/ditto/resultat_inference/inference/inference_1/result.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main(hp_inference, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ditto_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
